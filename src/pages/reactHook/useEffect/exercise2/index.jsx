import { useState, useEffect } from 'react';
import './styleScroll.css';
const Scroll = () => {
  const [scrollTop, setScrollTop] = useState(0);
  const handleScroll = () => {
    const clientScroll = document.documentElement.scrollTop;
    const height = document.documentElement.scrollHeight - document.documentElement.clientHeight;
    const scrolled = (clientScroll / height) * 100;

    setScrollTop(scrolled);
  };
  useEffect(() => {
    window.addEventListener('scroll', handleScroll);
    return () => window.removeEventListener('scroll', handleScroll);
  }, []);

  return (
    <div>
      <div className="scroll">
        <div className="stylesScroll" style={{ width: `${scrollTop}%` }}></div>
      </div>
      <p className="text">
        Yolo V4 for advanced Traffic Sign Recognition with synthetic training data generated by
        various GAN
      </p>
      <p className="text2">
        Christine Dewi1,2, Rung-Ching Chen1*, Yan-Ting Liu1, Xiaoyi Jiang3, Senior Member, IEEE, and
        Kristoko Dwi Hartomo2* 1Department of Information Management, Chaoyang University of
        Technology, Taichung, 41349, Taiwan. 2Faculty of Information Technology, Satya Wacana
        Christian University, Central Java, 50711, Indonesia. 3 Department of Mathematics and
        Computer Science, University of Münster, D-48149 Münster, Germany. Corresponding author:
        Rung-Ching Chen (e-mail: crching@cyut.edu.tw), Kristoko Dwi Hartomo (kristoko@uksw.edu).
        This paper is supported by the Ministry of Science and Technology, Taiwan. The Nos are
        MOST-107-2221-E-324 -018 -MY2 and MOST-109-2622-E-324 -004, Taiwan. This research is also
        partially sponsored by Chaoyang University of Technology (CYUT), Higher Education Sprout
        Project, Ministry of Education (MOE), Taiwan, under the project name: The R&D and the
        cultivation of talent for health-enhancement products., and Education and Culture Ministry
        Republic Indonesia for Grant Research PTUPT at 2019 – 2021. ABSTRACT Convolutional Neural
        Networks (CNN) achieves perfection in traffic sign identification with enough annotated
        training data. The dataset determines the quality of the complete visual system based on
        CNN. Unfortunately, databases for traffic signs from the majority of the worlds nations are
        few. In this scenario, Generative Adversarial Networks (GAN) may be employed to produce more
        realistic and varied training pictures to supplement the actual arrangement of images. The
        purpose of this research is to describe how the quality of synthetic pictures created by
        DCGAN, LSGAN, and WGAN is determined. Our work combines synthetic images with original
        images to enhance datasets and verify the effectiveness of synthetic datasets. We use
        different numbers and sizes of images for training. Likewise, the Structural Similarity
        Index (SSIM) and Mean Square Error (MSE) were employed to assess picture quality. Our study
        quantifies the SSIM difference between the synthetic and actual images. When additional
        images are used for training, the synthetic image exhibits a high degree of resemblance to
        the genuine image. The highest SSIM value was achieved when using 200 total images as input
        and 32×32 image size. Further, we augment the original picture dataset with synthetic
        pictures and compare the original image model to the synthesis image model. For this
        experiment, we are using the latest iterations of Yolo, Yolo V3, and Yolo V4. After mixing
        the real image with the synthesized image produced by LSGAN, the recognition performance has
        been improved, achieving an accuracy of 84.9% on Yolo V3 and an accuracy of 89.33% on Yolo
        V4. INDEX TERMS DCGAN, LSGAN, Synthetic Images, Traffic Sign, WGAN, Yolo V3, Yolo V4.I.
        INTRODUCTION Traffic sign identification has emerged as a critical study area in the science
        of computer vision in recent years. Moreover, it plays a critical part in advanced driver
        assistance systems, self-driving vehicles, and traffic safety [1][2][3]. In the previous
        research, Convolutional Neural Networks (CNN) [4] has achieved very good research results in
        traffic sign detection and recognition. A considerable quantity of data must be utilized in
        the neural network to ensure that the model is adequately trained and capable of recognizing
        traffic signs. As a result, if a significant quantity of labeled data is available,
        developing a CNN-based traffic detection model should not be difficult. Many researchers
        have done extensive research and discussion on the identification of traffic signs. They
        also provide many data sets for public use, such as the German Traffic Signals Dataset
        (GTSRB) [5][6], the Chinese Traffic Sign Database (TSRD) and Tsinghua Tencent 100K (TT100K)
        [7]. Researchers usually use open datasets or collect traffic signs through roads to do
        their experiments. Nevertheless, obtaining a huge quantity of high-quality images of traffic
        signs is not straightforward [8][9]. It takes a considerable amount of time, whether it is
        using a dashcam or on-site filming. In addition, the design and color of traffic signs are
        This work is licensed under a Creative Commons Attribution 4.0 License. For more
        information, see https://creativecommons.org/licenses/by/4.0/This article has been accepted
        for publication in a future issue of this journal, but has not been fully edited. Content
        may change prior to final publication. Citation information: DOI10.1109/ACCESS.2021.3094201,
        IEEE Access 2 different for each country, meaning that it is necessary to collect and mark
        traffic signs from different countries. Synthesizing images is a prominent problem in
        computer vision [10][11]. To acquire more varied and inexpensive training data, traffic sign
        pictures generated from standard templates have been routinely employed to train machine
        learning classification algorithms [12][13]. Deep Convolutional Generative Adversarial
        Network (DCGAN) was proposed by Alec Radford et al. [14][15] in 2016. DCGAN combines the
        Generative Adversarial Network (GAN) with CNN so that all GANs can get better and more
        stable training results. Other versions of GAN are Least Squares Generative Adversarial
        Networks (LSGAN) and Wasserstein Generative Adversarial Networks (WGAN) [16][17]. Both of
        them can better solve the problem of instability training due to GAN. Each GAN has achieved
        excellent results in producing synthetic image. Because of the absence of a training
        dataset, our studies use DCGAN, LSGAN, and WGAN to generate synthetic pictures. For Traffic
        Sign Detection (TSD), it is very important to detect small objects at high speeds accurately
        and quickly. Moreover, CNN can effectively detect and classify object such as Faster R-CNN
        [18], Single Shot Multibox Detector (SSD) [19], and You Only Look Once (Yolo) [20]. Yolo has
        the most significant influence under conditions that require faster time detection. It has a
        high-efficiency detection speed and high accuracy. The newest version of Yolo, Yolo V4 was
        proposed in 2020 [21]. The majority of modern scientific models need several GPUs for
        training with large mini-batch size. Usually, when training with one GPU makes the training
        process slow, heavy, and ineffective. Yolo V4 [21] approaches this problem by constructing
        an object detector trained on a single GPU with a smaller mini-batch size. This method makes
        it potential to train a super quick and precise object detector with a single 1080 Ti or
        2080 Ti GPU. This paper analyzes in detailed CNN models and feature extractors,
        specifically, Yolo V3 and Yolo V4 for object identification. Our study refined them using
        Taiwan prohibitory sign datasets that we created to detect traffic signs. Our dataset
        consists of no entry (Class P1), no stopping (Class P2), no parking (Class P3), and speed
        limit (Class P4). We have been unable to locate a research article that assesses a large
        number of object detectors based on deep learning that is expressly tuned to the traffic
        sign recognition problem domain while taking into account numerous crucial aspects such as
        mAP, IoU, and detection time. The primary contributions of this research are as follows: (1)
        High-quality prohibitory sign pictures are synthesized using DCGAN, LSGAN, and WGAN. (2) The
        development of a CNN-based solution for traffic sign classification tasks, as well as the
        augmentation of the CNN training set using created synthetic data, in order to enhance
        classification and recognition performance. (3) We proposed an experimental setting with
        various GAN style to generate synthetic image, after that we evaluate the synthetic image
        using SSIM and MSE. (4) The Yolo V3 and Yolo V4 model evaluation includes the mAP, detection
        time, IoU, and floating-point operations (FLOPS). (5) Experiments show that using synthetic
        image data generation using various GAN can improve all models IoU and performance. This
        research work is structured as follows. Section II discusses contemporarily published works.
        Section III details our recommended technique. The experiment and its findings are described
        in Section IV. Detailed discussion about our research describes in Section V. In Section VI,
        conclusions are stated and recommendations for further study are made. II. RELATED WORKS A.
        IMAGE RECOGNITION Image recognition is an important role in the field of computer vision.
        For humans, it is easy to recognize objects, but it is very difficult for machines. The
        machine needs to learn the meaning of each image, observe slowly, and test. According to the
        learning results, the machine can learn how to recognize the object. Shijin Song et al. [22]
        proposed a better CNN network architecture that allows small objects to be better detected,
        with less computation, and easier deployment. They eliminated the CNN network, significantly
        lowering the models size and operation time while preserving accuracy. At the same time, the
        fully connected layer is replaced with a fully convolutional layer, which improves the
        efficiency of calculation. Jing Tao et al. [23] were inspired by the Fully Convolution
        Network (FCN) and used the combination of Yolo to produce a new optimized Yolo. This
        combination models allows object detection to provide higher accuracy in traffic scenes. An
        average accuracy of 69.3% was obtained on the VOC07 and VOC12 datasets, while the
        traditional Yolo was only 64%. In traffic scenes, traffic signs are relatively small and
        make it impossible to detect the sign precisely. Ryo Hasegawa et al. [24] proposed a better
        recognition method in complex traffic scenes in Japan. The experiment use Yolo V2 and 5
        different image sizes as input. The multiscale images also implemented to make the model
        steady and train better. Chih-Chung Hsu et al. proposed a new architecture based on Densenet
        [25], called Common Fake Feature Network (CFFN). The architecture uses pairwise learning to
        optimize the network, and matching real images with fake images. The neural network captures
        the features and recognize them as fake images and real images well. The cross-entropy loss
        function used to optimize the classifiers method. Finally, the experimental results are
        significantly higher than other traditional methods. B. VARIOUS GAN Alec Radford et al.
        assessed the convolutional GANs architectural and topological restrictions in 2016. The
        technology, called Deep Convolutional GAN (DCGAN), is more stable in most situations
        [14][26]. GAN [27][28] has two parts that are simultaneously trained, namely generative (G)
        and discriminative (D). The This work is licensed under a Creative Commons Attribution 4.0
        License. For more information, see https://creativecommons.org/licenses/by/4.0/This article
        has been accepted for publication in a future issue of this journal, but has not been fully
        edited. Content may change prior to final publication. Citation information:
        DOI10.1109/ACCESS.2021.3094201, IEEE Access 3 discriminatory model is used to detect if a
        sample contains valid or invalid data. The generative model captures certain target
        information distribution to puzzle the discriminative model [29][30]. The D model is a
        binary classifier that classifies the G models data in the training system as either
        realistic or unrealistic. G minimizes its loss function by supplying data that D classifies
        as real, as modeled by Equation (1). 
         (1) We employ DCGAN to build a synthetic traffic sign picture in
        this work [31]. Following that, we will integrate the synthetic image with the real image in
        order to expand our dataset and enhance traffic sign recognition algorithms. DCGAN is a
        baseline model, other models build on it by adding additional restrictions or making
        enhancements. Numerous research efforts have been directed toward different GAN variations
        to improve the overall performance of GANs. Brock et al. [32] introduced models named
        BigGANs, which realized the work of generating high-resolution and different images from
        heterogeneous datasets. The image recognition algorithm can process high-resolution images
        and a wide range of samples from the difficult dataset, ImageNet. Karras et al. [15]
        suggested an alternative generator design called StyleGAN. The authors designed a new
        generator architecture that can dynamically vary the style of the generated picture
        depending on the latest information in all convolutional layers. By starting with low
        resolution, it helps to guide the full picture synthesis process which begins with low
        resolution and works its way up to high resolution. Li and Wand [33] proposed an efficient
        texture synthesis method named Markovian Generative Adversarial Networks (MGANs). It can
        decode brown noise straight into a realistic texture, but it can also decode pictures into
        the painting, which increases the texture synthesis quality. Jetchev et al. [34] introduced
        an architecture named spatial GAN (SGAN) which is very good for texture synthesis. This
        approach is capable of creating high-quality texture pictures and fusing numerous diverse
        source photos to create complex textures. There are two benefits of Least Squares Generative
        Adversarial Networks (LSGAN) over regular GANs. The first benefit of LSGANs is that they can
        create higher-quality pictures than normal GANs. Second, LSGANs are more stable in their
        performance throughout the learning process [35][36]. In reality, training GANs is a
        difficult challenge due to the instability of GAN learning. Recently, many articles have
        shown that the goal function affects the uncertainty of GANs learning [37]. In particular,
        reducing the usual GAN objective functions can cause gradient loss problems, which makes it
        difficult to update the generator. LSGANs overcome this barrier by penalizing samples
        depending on their distances to the decision boundary, which results in more gradients being
        generated when the generator is updated. Furthermore, demonstrate theoretically that the
        training instability of standard GANs is attributable to the objective functions
        mode-seeking tendency, while LSGANs display less mode-seeking activity. The algorithm of
        Wasserstein Generative Adversarial Networks (WGAN) [17] has been created to confront the
        instability in training networks [38], which is believed to be associated with the existence
        of undesirable sharp gradients of the GAN discriminator function. Yang et al. [39] adopted
        Wasserstein GAN for denoising low-dose CT images and attained a successful application in
        medical imaging reconstruction. In the synthesis data production module, WGAN is used to
        produce simulated fault signals in order to incrementally supplement minority fault classes,
        and the synthetic signals are used to balance the training dataset. C. PERFORMANCE
        EVALUATION OF SYNTHETIC IMAGES Structural Similarity Index (SSIM) [40][41] is employed to
        determine the structural similarity between two photographs. The traditional pictures SSIM
        assessment method calculates the SSIM index of the local block via the sliding window in the
        deformed picture. After obtaining the SSIM evaluation value of the whole picture, it
        normalizes all the local block evaluation indications to produce the overall SSIM evaluation
        value [41][42]. The SSIM metrics for brightness, contrast, and structural comparison are
        presented in Equation (2) and are computed as follows:
         (2) Where  is the average of x, 
        is the average of y,  is the variance of x,  is the variance of y, and  is the
        covariance of x and y.  and are small constants. The Mean Square Error (MSE) is
        obtained to compute the difference between estimated values and the real values of the
        quantity being estimated, which is squared as the square of the difference of pixels. The
        error is the difference between the estimators inferred value and the quantity to be
        estimated as indicated in Equation (3) [11].   (3) Where  describes the
        observed value, represents predicted value, and  is the number of data points. In this
        research, DCGAN, LSGAN, and WGAN-generated synthetic images will be assessed using SSIM and
        MSE. SSIM has a value between -1 and 1, which is meaning the higher is better. Smaller MSE
        values, on the other hand, imply a more positive outcome. D. YOLO V3 AND YOLO V4 Yolo V3 was
        introduced by Redmon et.al [43] in 2016. It splits the input image into (N × N) grids cells
        [44] with the similar size. Yolo V3 forecast bounding boxes and probabilities for each grid
        cell. Also, Yolo V3 utilizes multi-scale fusion to provide predictions, and a single neural
        network is used to gather and preprocess the holistic picture. In the earlier box
        forecasting, the dimension clusters are used as boxes to which the border boxes are
        assigned. Furthermore, the K-means algorithm is used to perform
      </p>
    </div>
  );
};

export default Scroll;
